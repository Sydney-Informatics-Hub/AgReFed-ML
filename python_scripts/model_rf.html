<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>python_scripts.model_rf API documentation</title>
<meta name="description" content="Random Forest Model with uncertainty estimates and feature importance â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>python_scripts.model_rf</code></h1>
</header>
<section id="section-intro">
<p>Random Forest Model with uncertainty estimates and feature importance.</p>
<p>This package is part of the machine learning project developed for the Agricultural Research Federation (AgReFed).</p>
<p>Copyright 2022 Sebastian Haan, Sydney Informatics Hub (SIH), The University of Sydney</p>
<p>This open-source software is released under the AGPL-3.0 License.</p>
<p>@author: Sebastian Haan</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Random Forest Model with uncertainty estimates and feature importance.


This package is part of the machine learning project developed for the Agricultural Research Federation (AgReFed).

Copyright 2022 Sebastian Haan, Sydney Informatics Hub (SIH), The University of Sydney

This open-source software is released under the AGPL-3.0 License.

@author: Sebastian Haan
&#34;&#34;&#34;

import matplotlib.pyplot as plt
import numpy as np
import os
import random
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.inspection import permutation_importance
from scipy.stats import spearmanr

print_info = False


def pred_ints(model, X, percentile=95):
        &#34;&#34;&#34;
        Predict standard deviation and CI using stats of all decision trees

        INPUT
        model: trained sklearn model
        X: input data matrix with shape (npoints,nfeatures)
        percentile: percentile of confidence interval

        RETURN
        stddev: standard deviation of prediction
        err_down: lower bound of confidence interval
        err_up: upper bound of confidence interval
        &#34;&#34;&#34;
        preds = []
        for pred in model.estimators_:
            preds.append(pred.predict(X))
        preds = np.asarray(preds)
        stddev = np.std(preds, axis =0)
        err_down = np.percentile(preds, (100 - percentile) / 2., axis = 0)
        err_up = np.percentile(preds, 100 - (100 - percentile) / 2., axis = 0)
        return stddev, err_down, err_up


def rf_train(X_train, y_train):
        &#34;&#34;&#34;
        Trains Random Fortest regression model with trainig data

        INPUT
        X: input data matrix with shape (npoints,nfeatures)
        y: target varable with shape (npoints)

        RETURN
        rf_model: trained sklearn RF model
        &#34;&#34;&#34;
        rf_reg = RandomForestRegressor(n_estimators=1000, min_samples_leaf=2, max_features = 0.3, random_state = 42) # &#39;reg:linear&#39; depreceasted 
        rf_reg.fit(X_train, y_train)
        return rf_reg
        


def rf_predict(X_test, rf_model, y_test = None, outpath = None):
        &#34;&#34;&#34;
        Returns Prediction for Random Forest regression model

        INPUT
        X_text: input datpoints in shape (ndata,n_feature). THe number of features has to be the same as for the training data
        xg_model: pre-trained XGboost regression model
        y_test: if True, uses true y data for normalized RMSE calculation

        Return
        ypred: predicted y values
        ypred_std: standard deviation of prediction
        rmse_test: RMSE of test data (if y_test is not None)
        &#34;&#34;&#34;
        ypred = rf_model.predict(X_test)
        ypred_std, _ , _ = pred_ints(rf_model, X_test, percentile=95)
        if y_test is not None:
                # calculate RMSE
                rmse_test = np.sqrt(np.mean((ypred - y_test)**2)) / y_test.std()
                if print_info: print(&#34;Random Forest normalized RMSE Test: &#34;, np.round(rmse_test, 4))
                if outpath is not None:
                        plt.figure()  # inches
                        plt.title(&#39;Random Forest Test Data&#39;)
                        plt.errorbar(y_test, ypred, ypred_std, linestyle=&#39;None&#39;, marker = &#39;o&#39;, c = &#39;b&#39;)
                        #plt.scatter(y_test, ypred, c = &#39;b&#39;)
                        plt.xlabel(&#39;y True&#39;)
                        plt.ylabel(&#39;y Predict&#39;)
                        plt.savefig(os.path.join(outpath,&#39;RF_test_pred_vs_true.png&#39;), dpi = 300)
                        plt.close(&#39;all&#39;)
        else:
                rmse_test = None
        return ypred, ypred_std, rmse_test


def rf_train_predict(X_train, y_train, X_test, y_test = None, outpath = None):
        &#34;&#34;&#34;
        Trains Random Forest regression model with trainig data and returns prediction for test data

        INPUT
        X_train: input data matrix with shape (npoints,nfeatures)
        y_train: target varable with shape (npoints)
        X_test: input data matrix with shape (npoints_test,nfeatures)
        y_test: target varable with shape (npoints_test)
        outpath: path to save plots

        RETURN
        ypred: predicted y values
        residuals: residuals of prediction
        &#34;&#34;&#34;

        # Train RF
        rf_model = rf_train(X_train, y_train)

        # Predict for X_test
        ypred, ypred_std, nrmse_test = rf_predict(X_test, rf_model, y_test = y_test, outpath = outpath)

        # calculate square errors
        if y_test is not None:
                residual = ypred - y_test
        else:
                residual = np.zeros_like(y_test)
        return ypred, residual


def test_rf(logspace = False, nsamples = 600, nfeatures = 14, ninformative = 12, noise = 0.2, outpath = None):
        &#34;&#34;&#34;
        Test RF model on synthetic data

        INPUT
        logspace: if True, uses logarithmic scale for features
        nsamples: number of samples
        nfeatures: number of features
        ninformative: number of informative features
        noise: noise level
        outpath: path to save plots

        &#34;&#34;&#34;
        # Create simulated data
        from sklearn.datasets import make_regression
        Xorig, yorig, coeffs = make_regression(n_samples=nsamples, 
                n_features=nfeatures, n_informative=ninformative, 
                n_targets=1, bias=2.0, tail_strength=0.2, noise=noise, shuffle=True, coef=True, random_state=42)
        if logspace:
                Xorig = np.exp(Xorig)
                yorig = np.exp(yorig/100)

        if outpath is not None: 
                os.makedirs(outpath, exist_ok = True)

        X_train, X_test, y_train, y_test = train_test_split(Xorig, yorig, test_size=0.5, random_state=42)

        # Run RF
        y_pred, residual = rf_train_predict(X_train, y_train, X_test, y_test = y_test, outpath = outpath)

        # Calculate normalized RMSE:
        nrmse = np.sqrt(np.nanmean(residual**2)) / y_test.std()
        nrmedse = np.sqrt(np.median(residual**2)) / y_test.std()
        if print_info:
                print(&#39;Normalized RMSE for test data: &#39;, np.round(nrmse,3))
                print(&#39;Normalized ROOT MEDIAM SE for test data: &#39;, np.round(nrmedse,3))
        #Feature Importance
        feature_importance = rf_factor_importance(X_train, y_train)
        if print_info:
                print(&#39;Model correlation coefficients:&#39;, coeffs )
                print(&#39;Feature Importance:&#39;, feature_importance)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="python_scripts.model_rf.pred_ints"><code class="name flex">
<span>def <span class="ident">pred_ints</span></span>(<span>model, X, percentile=95)</span>
</code></dt>
<dd>
<div class="desc"><p>Predict standard deviation and CI using stats of all decision trees</p>
<p>INPUT
model: trained sklearn model
X: input data matrix with shape (npoints,nfeatures)
percentile: percentile of confidence interval</p>
<p>RETURN
stddev: standard deviation of prediction
err_down: lower bound of confidence interval
err_up: upper bound of confidence interval</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pred_ints(model, X, percentile=95):
        &#34;&#34;&#34;
        Predict standard deviation and CI using stats of all decision trees

        INPUT
        model: trained sklearn model
        X: input data matrix with shape (npoints,nfeatures)
        percentile: percentile of confidence interval

        RETURN
        stddev: standard deviation of prediction
        err_down: lower bound of confidence interval
        err_up: upper bound of confidence interval
        &#34;&#34;&#34;
        preds = []
        for pred in model.estimators_:
            preds.append(pred.predict(X))
        preds = np.asarray(preds)
        stddev = np.std(preds, axis =0)
        err_down = np.percentile(preds, (100 - percentile) / 2., axis = 0)
        err_up = np.percentile(preds, 100 - (100 - percentile) / 2., axis = 0)
        return stddev, err_down, err_up</code></pre>
</details>
</dd>
<dt id="python_scripts.model_rf.rf_predict"><code class="name flex">
<span>def <span class="ident">rf_predict</span></span>(<span>X_test, rf_model, y_test=None, outpath=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns Prediction for Random Forest regression model</p>
<p>INPUT
X_text: input datpoints in shape (ndata,n_feature). THe number of features has to be the same as for the training data
xg_model: pre-trained XGboost regression model
y_test: if True, uses true y data for normalized RMSE calculation</p>
<p>Return
ypred: predicted y values
ypred_std: standard deviation of prediction
rmse_test: RMSE of test data (if y_test is not None)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rf_predict(X_test, rf_model, y_test = None, outpath = None):
        &#34;&#34;&#34;
        Returns Prediction for Random Forest regression model

        INPUT
        X_text: input datpoints in shape (ndata,n_feature). THe number of features has to be the same as for the training data
        xg_model: pre-trained XGboost regression model
        y_test: if True, uses true y data for normalized RMSE calculation

        Return
        ypred: predicted y values
        ypred_std: standard deviation of prediction
        rmse_test: RMSE of test data (if y_test is not None)
        &#34;&#34;&#34;
        ypred = rf_model.predict(X_test)
        ypred_std, _ , _ = pred_ints(rf_model, X_test, percentile=95)
        if y_test is not None:
                # calculate RMSE
                rmse_test = np.sqrt(np.mean((ypred - y_test)**2)) / y_test.std()
                if print_info: print(&#34;Random Forest normalized RMSE Test: &#34;, np.round(rmse_test, 4))
                if outpath is not None:
                        plt.figure()  # inches
                        plt.title(&#39;Random Forest Test Data&#39;)
                        plt.errorbar(y_test, ypred, ypred_std, linestyle=&#39;None&#39;, marker = &#39;o&#39;, c = &#39;b&#39;)
                        #plt.scatter(y_test, ypred, c = &#39;b&#39;)
                        plt.xlabel(&#39;y True&#39;)
                        plt.ylabel(&#39;y Predict&#39;)
                        plt.savefig(os.path.join(outpath,&#39;RF_test_pred_vs_true.png&#39;), dpi = 300)
                        plt.close(&#39;all&#39;)
        else:
                rmse_test = None
        return ypred, ypred_std, rmse_test</code></pre>
</details>
</dd>
<dt id="python_scripts.model_rf.rf_train"><code class="name flex">
<span>def <span class="ident">rf_train</span></span>(<span>X_train, y_train)</span>
</code></dt>
<dd>
<div class="desc"><p>Trains Random Fortest regression model with trainig data</p>
<p>INPUT
X: input data matrix with shape (npoints,nfeatures)
y: target varable with shape (npoints)</p>
<p>RETURN
rf_model: trained sklearn RF model</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rf_train(X_train, y_train):
        &#34;&#34;&#34;
        Trains Random Fortest regression model with trainig data

        INPUT
        X: input data matrix with shape (npoints,nfeatures)
        y: target varable with shape (npoints)

        RETURN
        rf_model: trained sklearn RF model
        &#34;&#34;&#34;
        rf_reg = RandomForestRegressor(n_estimators=1000, min_samples_leaf=2, max_features = 0.3, random_state = 42) # &#39;reg:linear&#39; depreceasted 
        rf_reg.fit(X_train, y_train)
        return rf_reg</code></pre>
</details>
</dd>
<dt id="python_scripts.model_rf.rf_train_predict"><code class="name flex">
<span>def <span class="ident">rf_train_predict</span></span>(<span>X_train, y_train, X_test, y_test=None, outpath=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Trains Random Forest regression model with trainig data and returns prediction for test data</p>
<p>INPUT
X_train: input data matrix with shape (npoints,nfeatures)
y_train: target varable with shape (npoints)
X_test: input data matrix with shape (npoints_test,nfeatures)
y_test: target varable with shape (npoints_test)
outpath: path to save plots</p>
<p>RETURN
ypred: predicted y values
residuals: residuals of prediction</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rf_train_predict(X_train, y_train, X_test, y_test = None, outpath = None):
        &#34;&#34;&#34;
        Trains Random Forest regression model with trainig data and returns prediction for test data

        INPUT
        X_train: input data matrix with shape (npoints,nfeatures)
        y_train: target varable with shape (npoints)
        X_test: input data matrix with shape (npoints_test,nfeatures)
        y_test: target varable with shape (npoints_test)
        outpath: path to save plots

        RETURN
        ypred: predicted y values
        residuals: residuals of prediction
        &#34;&#34;&#34;

        # Train RF
        rf_model = rf_train(X_train, y_train)

        # Predict for X_test
        ypred, ypred_std, nrmse_test = rf_predict(X_test, rf_model, y_test = y_test, outpath = outpath)

        # calculate square errors
        if y_test is not None:
                residual = ypred - y_test
        else:
                residual = np.zeros_like(y_test)
        return ypred, residual</code></pre>
</details>
</dd>
<dt id="python_scripts.model_rf.test_rf"><code class="name flex">
<span>def <span class="ident">test_rf</span></span>(<span>logspace=False, nsamples=600, nfeatures=14, ninformative=12, noise=0.2, outpath=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Test RF model on synthetic data</p>
<p>INPUT
logspace: if True, uses logarithmic scale for features
nsamples: number of samples
nfeatures: number of features
ninformative: number of informative features
noise: noise level
outpath: path to save plots</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_rf(logspace = False, nsamples = 600, nfeatures = 14, ninformative = 12, noise = 0.2, outpath = None):
        &#34;&#34;&#34;
        Test RF model on synthetic data

        INPUT
        logspace: if True, uses logarithmic scale for features
        nsamples: number of samples
        nfeatures: number of features
        ninformative: number of informative features
        noise: noise level
        outpath: path to save plots

        &#34;&#34;&#34;
        # Create simulated data
        from sklearn.datasets import make_regression
        Xorig, yorig, coeffs = make_regression(n_samples=nsamples, 
                n_features=nfeatures, n_informative=ninformative, 
                n_targets=1, bias=2.0, tail_strength=0.2, noise=noise, shuffle=True, coef=True, random_state=42)
        if logspace:
                Xorig = np.exp(Xorig)
                yorig = np.exp(yorig/100)

        if outpath is not None: 
                os.makedirs(outpath, exist_ok = True)

        X_train, X_test, y_train, y_test = train_test_split(Xorig, yorig, test_size=0.5, random_state=42)

        # Run RF
        y_pred, residual = rf_train_predict(X_train, y_train, X_test, y_test = y_test, outpath = outpath)

        # Calculate normalized RMSE:
        nrmse = np.sqrt(np.nanmean(residual**2)) / y_test.std()
        nrmedse = np.sqrt(np.median(residual**2)) / y_test.std()
        if print_info:
                print(&#39;Normalized RMSE for test data: &#39;, np.round(nrmse,3))
                print(&#39;Normalized ROOT MEDIAM SE for test data: &#39;, np.round(nrmedse,3))
        #Feature Importance
        feature_importance = rf_factor_importance(X_train, y_train)
        if print_info:
                print(&#39;Model correlation coefficients:&#39;, coeffs )
                print(&#39;Feature Importance:&#39;, feature_importance)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="python_scripts" href="index.html">python_scripts</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="python_scripts.model_rf.pred_ints" href="#python_scripts.model_rf.pred_ints">pred_ints</a></code></li>
<li><code><a title="python_scripts.model_rf.rf_predict" href="#python_scripts.model_rf.rf_predict">rf_predict</a></code></li>
<li><code><a title="python_scripts.model_rf.rf_train" href="#python_scripts.model_rf.rf_train">rf_train</a></code></li>
<li><code><a title="python_scripts.model_rf.rf_train_predict" href="#python_scripts.model_rf.rf_train_predict">rf_train_predict</a></code></li>
<li><code><a title="python_scripts.model_rf.test_rf" href="#python_scripts.model_rf.test_rf">test_rf</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>